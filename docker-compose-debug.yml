version: '2'

volumes:
  es:

services:
  search:
    image: robcurrie/searchjupyter
    ports:
      - "80:5000"

    # Build and run out of local directory with auto-reload
    build: .
    volumes:
      - .:/usr/src/app
      - /data/notebooks:/notebooks
    command: --python-autoreload=1 --processes=1 --threads=1

  nginx:
    image: nginx:stable-alpine
    volumes:
      - /data/notebooks:/usr/share/nginx/html/notebooks

  nbviewer:
    image: nbviewer
    build:
      context: .
      dockerfile: Dockerfile.nbviewer
    volumes:
      - /data/notebooks:/notebooks
    command: python3 -m nbviewer --port=8080 --no-cache --localfiles=/notebooks --base_url=/nbviewer

  es:
    image: docker.elastic.co/elasticsearch/elasticsearch:5.4.3
    ports:
      - "9200:9200"
    volumes:
      - es:/usr/share/elasticsearch/data
    environment:
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
      - http.cors.enabled=true
      - http.cors.allow-origin=*
      - http.cors.allow-headers=X-Requested-With, Content-Type, Content-Length, Access-Control-Allow-Headers, Authorization


  # crawl:
  #   image: robcurrie/searchcgt
  #   links:
  #     - ipfs
  #     - es
  #   volumes:
  #     - ./pyensembl:/root/.cache/pyensembl
  #     - .:/usr/src/app
  #   entrypoint: python searchcgt/crawl.py -t 60 -i 1 QmWPSzKERs6KAjb8QfSXViFqyEUn3VZYYnXjgG6hJwXWYK

